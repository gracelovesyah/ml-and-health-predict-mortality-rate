{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe71412-9242-4482-8540-cfa5e790c6ce",
   "metadata": {},
   "source": [
    "by wedad\\\n",
    "Hey team this file contains the best combined ensemble models from for Decision Tree and Regression model experimentations\\\n",
    "I'll be comparing them to the baseline model found in baseline_model.ipynb\\\n",
    "The columns dropped are selected from '4_FeatureEngineeringRegression' file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670f11f-75b7-4a18-ac49-fa63f789bce3",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29242cb7-c951-45f2-87d3-ac60b6f99728",
   "metadata": {},
   "source": [
    "#### Importing Relevant Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb0ece1-53a0-4306-a838-7f4ea4907952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bcee1d-f28a-4475-9d2b-ebdf440360c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>142.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>144.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>153.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9806</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>141.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9807</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>141.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9808</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9809 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dod  gender  age  Albumin  Creatinine  Hemoglobin  INR(PT)    PT  \\\n",
       "0       0       1   73      3.6         1.2         9.4      3.2  13.8   \n",
       "1       0       0   24      4.1         0.5        10.2      1.2  15.7   \n",
       "2       0       0   54      4.1         0.4        10.2      1.0  14.4   \n",
       "3       0       1   84      3.5         1.1        10.2      1.6  18.7   \n",
       "4       0       0   59      3.6         0.6        10.2      1.7  12.4   \n",
       "...   ...     ...  ...      ...         ...         ...      ...   ...   \n",
       "9804    0       1   61      3.3         3.6        10.2      1.5  13.1   \n",
       "9805    0       1   74      3.5         0.6        10.2      1.2  13.6   \n",
       "9806    0       1   58      4.1         0.6        10.2      0.9   9.3   \n",
       "9807    1       1   84      4.0         3.4        12.2      1.1  17.9   \n",
       "9808    0       1   56      3.2         6.9        10.2      1.3  25.9   \n",
       "\n",
       "      Sodium  Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "0      138.0           16.0                               48.0   \n",
       "1      143.0            6.0                               56.0   \n",
       "2      142.0           22.0                               48.0   \n",
       "3      144.0           17.0                               56.0   \n",
       "4      153.0            8.0                               70.0   \n",
       "...      ...            ...                                ...   \n",
       "9804   138.0           23.0                               62.0   \n",
       "9805   138.0            6.0                               56.0   \n",
       "9806   141.0            8.0                               56.0   \n",
       "9807   141.0           88.0                               56.0   \n",
       "9808   137.0           43.0                               56.0   \n",
       "\n",
       "      Arterial Blood Pressure systolic  Heart Rate  Respiratory Rate  \\\n",
       "0                                101.0        84.0              20.0   \n",
       "1                                114.0        59.0              16.0   \n",
       "2                                130.0        59.0              24.0   \n",
       "3                                114.0        89.0              21.0   \n",
       "4                                 91.0        99.0              21.0   \n",
       "...                                ...         ...               ...   \n",
       "9804                             103.0        89.0              20.0   \n",
       "9805                             114.0       107.0              22.0   \n",
       "9806                             114.0        78.0              10.0   \n",
       "9807                             114.0       101.0              25.0   \n",
       "9808                             114.0        88.0              19.0   \n",
       "\n",
       "      hypertension  chronic_kidney_disease  sepsis  Intercept  \n",
       "0                1                       0       0          1  \n",
       "1                0                       0       0          1  \n",
       "2                1                       0       0          1  \n",
       "3                1                       0       0          1  \n",
       "4                1                       0       1          1  \n",
       "...            ...                     ...     ...        ...  \n",
       "9804             0                       1       0          1  \n",
       "9805             1                       0       0          1  \n",
       "9806             0                       0       0          1  \n",
       "9807             1                       1       0          1  \n",
       "9808             0                       0       0          1  \n",
       "\n",
       "[9809 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aki_df = pd.read_csv('../../data/df_final_AKI.csv')\n",
    "aki_df = aki_df.drop(columns=['Unnamed: 0', 'subject_id'])\n",
    "aki_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d0e44-71a8-4ed3-8dc6-022dd5f1e6ae",
   "metadata": {},
   "source": [
    "## Full Feature Set Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6157ad2b-8b51-45c8-b868-4d90170ab7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5f711-7028-426d-874c-c1fbc2dce891",
   "metadata": {
    "tags": []
   },
   "source": [
    "### training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c3aaa9-ee7b-41f4-9a41-2eac4b0a8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = aki_df.drop(columns=['dod'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=seed_list[0])\n",
    "model_desc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06daebed-fa7b-4f7f-b526-1e2973b360d8",
   "metadata": {},
   "source": [
    "#### Linear Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1499257-1532-403e-9335-7deeda3e2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_sampling_methods = [None,  RandomOverSampler(),  SMOTE(), ADASYN(),RandomUnderSampler(), SMOTEENN(), SMOTETomek(), NearMiss()]\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "ridge_model = linear_model.Ridge(alpha=0, solver='cholesky')\n",
    "lasso_model = linear_model.Lasso(alpha=0.00001)\n",
    "EN_model = linear_model.ElasticNet(alpha=0.1)\n",
    "bayridge_model = linear_model.BayesianRidge()\n",
    "\n",
    "linear_model_list = [lin_reg, ridge_model, lasso_model, EN_model, bayridge_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cc032f-39f7-4659-898c-55569eef5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearEnsemble_Resampled(model_list, model_desc, sampling_methods, x_train, y_train, x_test, y_test,seed_list, majority_vote, title='Combined Resampled Ensemble'):\n",
    "    final_prediction = []\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "   \n",
    "    for model in model_list: \n",
    "        prediction_list = []\n",
    "        for samp in sampling_methods:\n",
    "            x_train_temp = x_train\n",
    "            y_train_temp = y_train\n",
    "            if samp != None:\n",
    "                x_train_temp, y_train_temp = samp.fit_resample(x_train, y_train)\n",
    "            model.fit(x_train_temp, y_train_temp)\n",
    "            y_pred_lin = model.predict(x_test)\n",
    "            y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred_lin]\n",
    "            prediction_list.append(y_pred_bin)\n",
    "#                 prediction_list = [a + b for a, b in zip(prediction_list, y_pred_bin)]\n",
    "# #                 prediction_list.append(y_pred_bin)\n",
    "                \n",
    "    prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "    final_prediction = []\n",
    "    print(\"Number of votes\")\n",
    "    print(set(prediction_list))\n",
    "    for pred in prediction_list:\n",
    "        if pred > majority_vote:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "                \n",
    "    # print(set(prediction_list))\n",
    "    total_acc += accuracy_score(y_test, final_prediction)\n",
    "    total_pre += precision_score(y_test, final_prediction)\n",
    "    total_rec += recall_score(y_test, final_prediction)\n",
    "    total_f1 += f1_score(y_test, final_prediction)\n",
    "    \n",
    "    model_desc.append([\n",
    "        \"linear Regression Ensemble\",\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "                      ])\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"{title}\")\n",
    "    print('--------------------------------------------')\n",
    "    print(\"Accuracy:\", total_acc/total)\n",
    "    print(\"Precision: \", total_pre/total)\n",
    "    print(\"recall: \", total_rec/total)\n",
    "    print(\"f1_score: \", total_f1/total)\n",
    "    print('--------------------------------------------')\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "    plt.show()\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1a7572-d8bc-49e6-a55b-b32bc8063333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of votes\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Linear full feature Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.7849133537206932\n",
      "Precision:  0.3828125\n",
      "recall:  0.4427710843373494\n",
      "f1_score:  0.41061452513966484\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_prediction =  linearEnsemble_Resampled(linear_model_list, model_desc, linear_sampling_methods, x_train, y_train, x_test, y_test, seed_list, 6, title=f'Linear full feature Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb867b2-97f0-45b4-8604-d159bb927949",
   "metadata": {},
   "source": [
    "#### Logistic Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d328f48-f0c3-4e40-8c0c-f7fdf690e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lbgfs = linear_model.LogisticRegression(penalty='l2', solver= 'lbfgs', class_weight = 'balanced', max_iter=1000, C=0.1)\n",
    "log_liblinear = linear_model.LogisticRegression(penalty='l1', solver= 'liblinear', class_weight = None, max_iter=1000, C=0.1)\n",
    "log_saga = linear_model.LogisticRegression(penalty='l2', solver= 'saga', class_weight = None, max_iter=1000, C=0.001)\n",
    "\n",
    "model_list = [log_lbgfs, log_liblinear, log_saga]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141cbe5a-516d-47b8-9822-05d99ee59c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticEnsemble(model_list, model_desc, x_train, y_train, x_test, y_test, title='Combined Ensemble'):\n",
    "    prediction_list = []\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "    prediction_list = []\n",
    "    for model in model_list:\n",
    "        x_train_temp = x_train\n",
    "        y_train_temp = y_train\n",
    "        model.fit(x_train_temp, y_train_temp)\n",
    "        y_pred_log = model.predict(x_test)\n",
    "        prediction_list.append(y_pred_log)\n",
    "\n",
    "    prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "    final_prediction = []\n",
    "    for pred in prediction_list:\n",
    "        if pred >1:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "            \n",
    "    total_acc += accuracy_score(y_test, final_prediction)\n",
    "    total_pre += precision_score(y_test, final_prediction)\n",
    "    total_rec += recall_score(y_test, final_prediction)\n",
    "    total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "\n",
    "    model_desc.append([\n",
    "        \"logistic Regression Ensemble\",\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "                      ])\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"{title}\")\n",
    "    print('--------------------------------------------')\n",
    "    print(\"Accuracy:\", total_acc/total)\n",
    "    print(\"Precision: \", total_pre/total)\n",
    "    print(\"recall: \", total_rec/total)\n",
    "    print(\"f1_score: \", total_f1/total)\n",
    "    print('--------------------------------------------')\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "    plt.show()\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d194626-416d-467e-9556-a58982a60438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full feature Logistic Combined Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8414882772680938\n",
      "Precision:  0.6\n",
      "recall:  0.1897590361445783\n",
      "f1_score:  0.2883295194508009\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logistic_prediction = logisticEnsemble(model_list, model_desc, x_train, y_train, x_test, y_test, title='full feature Logistic Combined Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5d501-54b4-4bb5-ab54-83e1801bb4f1",
   "metadata": {},
   "source": [
    "### Decision Tree Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f708f119-4548-406d-8b04-c8c09ce51e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = []\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f1 = 0\n",
    "total = len(seed_list)\n",
    "\n",
    "#Near Miss Sampled\n",
    "best_recall = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')\n",
    "# No sampling\n",
    "best_accuracy = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')\n",
    "\n",
    "#SMOTEK sampling\n",
    "best_f1 = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a815a5d-d08b-48e2-bba7-4d4a68d60f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full feature Ensemble Decision Tree\n",
      "--------------------------------------------\n",
      "Accuracy: 0.7838939857288482\n",
      "Precision:  0.38613861386138615\n",
      "recall:  0.46987951807228917\n",
      "f1_score:  0.4239130434782609\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_list = []\n",
    "    \n",
    "x_train_nearMiss, y_train_nearMiss = NearMiss().fit_resample(x_train, y_train)\n",
    "x_train_smotek, y_train_smotek = SMOTETomek().fit_resample(x_train, y_train)\n",
    "\n",
    "best_f1.fit(x_train_smotek, y_train_smotek)\n",
    "    \n",
    "best_recall.fit(x_train_nearMiss, y_train_nearMiss)\n",
    "    \n",
    "best_accuracy.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "y_pred_log1 = best_f1.predict(x_test)\n",
    "y_pred_log2 = best_recall.predict(x_test)\n",
    "y_pred_log3 = best_accuracy.predict(x_test) \n",
    "\n",
    "prediction_list.append(y_pred_log1)\n",
    "prediction_list.append(y_pred_log2)\n",
    "prediction_list.append(y_pred_log3)\n",
    "            \n",
    "prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "# print(set(prediction_list))\n",
    "\n",
    "final_prediction = []\n",
    "for pred in prediction_list:\n",
    "    if pred >1:\n",
    "        final_prediction.append(1)\n",
    "    else:\n",
    "        final_prediction.append(0)\n",
    "            \n",
    "    # print(set(prediction_list))\n",
    "total_acc += accuracy_score(y_test, final_prediction)\n",
    "total_pre += precision_score(y_test, final_prediction)\n",
    "total_rec += recall_score(y_test, final_prediction)\n",
    "total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "model_desc.append([\n",
    "    \"linear Regression Ensemble\",\n",
    "    total_acc/total,\n",
    "    total_pre/total,\n",
    "    total_rec/total,\n",
    "    total_f1/total\n",
    "                    ])\n",
    "\n",
    "    # Evaluate\n",
    "print(f\"full feature Ensemble Decision Tree\")\n",
    "print('--------------------------------------------')\n",
    "print(\"Accuracy:\", total_acc/total)\n",
    "print(\"Precision: \", total_pre/total)\n",
    "print(\"recall: \", total_rec/total)\n",
    "print(\"f1_score: \", total_f1/total)\n",
    "print('--------------------------------------------')\n",
    "\n",
    "decisionTree_prediction = final_prediction\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f223c11-defc-4f94-96b8-d27af74b180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of best Logistic, Linear and Decision Tree Classifiers using full features\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8277268093781855\n",
      "Precision:  0.48739495798319327\n",
      "recall:  0.3493975903614458\n",
      "f1_score:  0.40701754385964917\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ensemble_prediction = [linear_prediction, logistic_prediction, decisionTree_prediction]\n",
    "ensemble_prediction = [sum(x) for x in zip(*ensemble_prediction)]\n",
    "final_prediction = []\n",
    "for ens in ensemble_prediction:\n",
    "    if ens >1:\n",
    "        final_prediction.append(1)\n",
    "    else:\n",
    "        final_prediction.append(0)\n",
    "\n",
    "model_desc.append([\n",
    "    \"Ensemble Logistic+Linear+Decision Tree\",\n",
    "    accuracy_score(y_test, final_prediction),\n",
    "    precision_score(y_test, final_prediction),\n",
    "    recall_score(y_test, final_prediction),\n",
    "    f1_score(y_test, final_prediction)\n",
    "                      ])        \n",
    "        \n",
    "\n",
    "print(f\"Ensemble of best Logistic, Linear and Decision Tree Classifiers using full features\")\n",
    "print('--------------------------------------------')\n",
    "print(\"Accuracy:\", accuracy_score(y_test, final_prediction))\n",
    "print(\"Precision: \", precision_score(y_test, final_prediction))\n",
    "print(\"recall: \", recall_score(y_test, final_prediction))\n",
    "print(\"f1_score: \", f1_score(y_test, final_prediction))\n",
    "print('--------------------------------------------')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086bde7c-8428-4a2c-b80b-3a2aab5000bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Feature Ensemble Models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear Regression Ensemble</td>\n",
       "      <td>0.784913</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.442771</td>\n",
       "      <td>0.410615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic Regression Ensemble</td>\n",
       "      <td>0.841488</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.189759</td>\n",
       "      <td>0.288330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear Regression Ensemble</td>\n",
       "      <td>0.783894</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.423913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble Logistic+Linear+Decision Tree</td>\n",
       "      <td>0.827727</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.407018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  accuracy  precision    recall  \\\n",
       "0              linear Regression Ensemble  0.784913   0.382812  0.442771   \n",
       "1            logistic Regression Ensemble  0.841488   0.600000  0.189759   \n",
       "2              linear Regression Ensemble  0.783894   0.386139  0.469880   \n",
       "3  Ensemble Logistic+Linear+Decision Tree  0.827727   0.487395  0.349398   \n",
       "\n",
       "   F1 score  \n",
       "0  0.410615  \n",
       "1  0.288330  \n",
       "2  0.423913  \n",
       "3  0.407018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_desc\n",
    "print(\"Full Feature Ensemble Models\")\n",
    "model_comparison_DF = pd.DataFrame(model_desc, columns=['model', 'accuracy', 'precision', 'recall', 'F1 score'])\n",
    "model_comparison_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad56ab5-1888-4a99-b179-1da94445b77f",
   "metadata": {},
   "source": [
    "Looking at the dataframe below, It appears that the ensembled models\\\n",
    "have ea tendency to label and mislabel in a similar manner.\n",
    "most guessed labels appears to have 2 or more votes, and although this sometimes\n",
    "captures the dod, it also equally misses these labels in a ratio to 3:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6026062b-7743-407b-82f9-f30fede97b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Feature Prediction Comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guessed label</th>\n",
       "      <th>actual label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8403</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      guessed label  actual label\n",
       "8403              3             0\n",
       "8207              1             0\n",
       "1333              2             1\n",
       "6758              0             0\n",
       "4936              2             0\n",
       "...             ...           ...\n",
       "3081              0             0\n",
       "8008              0             0\n",
       "7674              0             1\n",
       "9641              0             0\n",
       "3527              0             0\n",
       "\n",
       "[1962 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Full Feature Prediction Comparison\")\n",
    "prediction_comparison = pd.DataFrame(\n",
    "    {'guessed label': ensemble_prediction,\n",
    "     'actual label': y_test,\n",
    "    })\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "prediction_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a95c0e-96ca-473f-9a27-58e3aa8edbec",
   "metadata": {},
   "source": [
    "## Reduced Feature Set Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b09052a-5c93-4b4f-a7fe-7be38ddcd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7f512-fef2-451f-a730-aa5556260cda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f3c6aa-1204-44c5-8f5b-eec241b14d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = aki_df.drop(columns=['dod', 'Sodium','Hemoglobin','gender','hypertension','Intercept'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=seed_list[0])\n",
    "model_desc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81603f1c-a450-4e1d-943c-3836a162ff32",
   "metadata": {},
   "source": [
    "#### Linear Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9486e877-19b9-4440-93cc-8f91837e20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_sampling_methods = [None,  RandomOverSampler(),  SMOTE(), ADASYN(),RandomUnderSampler(), SMOTEENN(), SMOTETomek(), NearMiss()]\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "ridge_model = linear_model.Ridge(alpha=0, solver='cholesky')\n",
    "lasso_model = linear_model.Lasso(alpha=0.00001)\n",
    "EN_model = linear_model.ElasticNet(alpha=0.1)\n",
    "bayridge_model = linear_model.BayesianRidge()\n",
    "\n",
    "linear_model_list = [lin_reg, ridge_model, lasso_model, EN_model, bayridge_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf6aa47-4d10-42e3-89c1-0179208ff061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearEnsemble_Resampled(model_list, model_desc, sampling_methods, x_train, y_train, x_test, y_test,seed_list, majority_vote, title='Combined Resampled Ensemble'):\n",
    "    final_prediction = []\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "   \n",
    "    for model in model_list: \n",
    "        prediction_list = []\n",
    "        for samp in sampling_methods:\n",
    "            x_train_temp = x_train\n",
    "            y_train_temp = y_train\n",
    "            if samp != None:\n",
    "                x_train_temp, y_train_temp = samp.fit_resample(x_train, y_train)\n",
    "            model.fit(x_train_temp, y_train_temp)\n",
    "            y_pred_lin = model.predict(x_test)\n",
    "            y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred_lin]\n",
    "            prediction_list.append(y_pred_bin)\n",
    "#                 prediction_list = [a + b for a, b in zip(prediction_list, y_pred_bin)]\n",
    "# #                 prediction_list.append(y_pred_bin)\n",
    "                \n",
    "    prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "    final_prediction = []\n",
    "    print(\"Number of votes\")\n",
    "    print(set(prediction_list))\n",
    "    for pred in prediction_list:\n",
    "        if pred > majority_vote:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "                \n",
    "    # print(set(prediction_list))\n",
    "    total_acc += accuracy_score(y_test, final_prediction)\n",
    "    total_pre += precision_score(y_test, final_prediction)\n",
    "    total_rec += recall_score(y_test, final_prediction)\n",
    "    total_f1 += f1_score(y_test, final_prediction)\n",
    "    \n",
    "    model_desc.append([\n",
    "        \"linear Regression Ensemble\",\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "                      ])\n",
    "\n",
    "    # Evaluate\n",
    "    print(f\"{title}\")\n",
    "    print('--------------------------------------------')\n",
    "    print(\"Accuracy:\", total_acc/total)\n",
    "    print(\"Precision: \", total_pre/total)\n",
    "    print(\"recall: \", total_rec/total)\n",
    "    print(\"f1_score: \", total_f1/total)\n",
    "    print('--------------------------------------------')\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "    plt.show()\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a1327b-8e51-4175-9a88-3fe4b3303683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of votes\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Linear Sampled Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.7854230377166157\n",
      "Precision:  0.38734177215189874\n",
      "recall:  0.4608433734939759\n",
      "f1_score:  0.42090784044016505\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_prediction =  linearEnsemble_Resampled(linear_model_list, model_desc, linear_sampling_methods, x_train, y_train, x_test, y_test, seed_list, 6, title=f'Linear Sampled Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61890eb0-2cdf-4cf9-bd4f-ad5442ae1b08",
   "metadata": {},
   "source": [
    "#### Logistic Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a8ba64-844e-4391-a8af-6d7212be69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lbgfs = linear_model.LogisticRegression(penalty='l2', solver= 'lbfgs', class_weight = 'balanced', max_iter=1000, C=0.1)\n",
    "log_liblinear = linear_model.LogisticRegression(penalty='l1', solver= 'liblinear', class_weight = None, max_iter=1000, C=0.1)\n",
    "log_saga = linear_model.LogisticRegression(penalty='l2', solver= 'saga', class_weight = None, max_iter=1000, C=0.001)\n",
    "\n",
    "model_list = [log_lbgfs, log_liblinear, log_saga]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9d000c-2563-41e3-95cf-735650d387a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticEnsemble(model_list, model_desc, x_train, y_train, x_test, y_test, title='Combined Ensemble'):\n",
    "    prediction_list = []\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "    prediction_list = []\n",
    "    for model in model_list:\n",
    "        x_train_temp = x_train\n",
    "        y_train_temp = y_train\n",
    "        model.fit(x_train_temp, y_train_temp)\n",
    "        y_pred_log = model.predict(x_test)\n",
    "        prediction_list.append(y_pred_log)\n",
    "\n",
    "    prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "    final_prediction = []\n",
    "    for pred in prediction_list:\n",
    "        if pred >1:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "            \n",
    "    total_acc += accuracy_score(y_test, final_prediction)\n",
    "    total_pre += precision_score(y_test, final_prediction)\n",
    "    total_rec += recall_score(y_test, final_prediction)\n",
    "    total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "\n",
    "    model_desc.append([\n",
    "        \"logistic Regression Ensemble\",\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "                      ])\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"{title}\")\n",
    "    print('--------------------------------------------')\n",
    "    print(\"Accuracy:\", total_acc/total)\n",
    "    print(\"Precision: \", total_pre/total)\n",
    "    print(\"recall: \", total_rec/total)\n",
    "    print(\"f1_score: \", total_f1/total)\n",
    "    print('--------------------------------------------')\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "    plt.show()\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b79dfd-c3cc-4abc-bef3-f0a359c06777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Feature Set Logistic Combined Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8430173292558614\n",
      "Precision:  0.6132075471698113\n",
      "recall:  0.19578313253012047\n",
      "f1_score:  0.2968036529680365\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logistic_prediction = logisticEnsemble(model_list, model_desc, x_train, y_train, x_test, y_test, title='Reduced Feature Set Logistic Combined Ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b390f2d-5d94-4e21-b616-98ca5fa10e6e",
   "metadata": {},
   "source": [
    "### Decision Tree Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa5deac3-30a6-483e-9ff9-011467738af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = []\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f1 = 0\n",
    "total = len(seed_list)\n",
    "\n",
    "#Near Miss Sampled\n",
    "best_recall = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')\n",
    "# No sampling\n",
    "best_accuracy = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')\n",
    "\n",
    "#SMOTEK sampling\n",
    "best_f1 = DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
    "                       random_state=0, splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93de32e0-d612-4919-97cd-bb84e43f690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Ensemble Decision Tree\n",
      "--------------------------------------------\n",
      "Accuracy: 0.7787971457696228\n",
      "Precision:  0.373134328358209\n",
      "recall:  0.45180722891566266\n",
      "f1_score:  0.40871934604904636\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_list = []\n",
    "    \n",
    "x_train_nearMiss, y_train_nearMiss = NearMiss().fit_resample(x_train, y_train)\n",
    "x_train_smotek, y_train_smotek = SMOTETomek().fit_resample(x_train, y_train)\n",
    "\n",
    "best_f1.fit(x_train_smotek, y_train_smotek)\n",
    "    \n",
    "best_recall.fit(x_train_nearMiss, y_train_nearMiss)\n",
    "    \n",
    "best_accuracy.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "y_pred_log1 = best_f1.predict(x_test)\n",
    "y_pred_log2 = best_recall.predict(x_test)\n",
    "y_pred_log3 = best_accuracy.predict(x_test) \n",
    "\n",
    "prediction_list.append(y_pred_log1)\n",
    "prediction_list.append(y_pred_log2)\n",
    "prediction_list.append(y_pred_log3)\n",
    "            \n",
    "prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "# print(set(prediction_list))\n",
    "\n",
    "final_prediction = []\n",
    "for pred in prediction_list:\n",
    "    if pred >1:\n",
    "        final_prediction.append(1)\n",
    "    else:\n",
    "        final_prediction.append(0)\n",
    "            \n",
    "    # print(set(prediction_list))\n",
    "total_acc += accuracy_score(y_test, final_prediction)\n",
    "total_pre += precision_score(y_test, final_prediction)\n",
    "total_rec += recall_score(y_test, final_prediction)\n",
    "total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "model_desc.append([\n",
    "    \"linear Regression Ensemble\",\n",
    "    total_acc/total,\n",
    "    total_pre/total,\n",
    "    total_rec/total,\n",
    "    total_f1/total\n",
    "                    ])\n",
    "\n",
    "    # Evaluate\n",
    "print(f\"Resampled Ensemble Decision Tree\")\n",
    "print('--------------------------------------------')\n",
    "print(\"Accuracy:\", total_acc/total)\n",
    "print(\"Precision: \", total_pre/total)\n",
    "print(\"recall: \", total_rec/total)\n",
    "print(\"f1_score: \", total_f1/total)\n",
    "print('--------------------------------------------')\n",
    "\n",
    "decisionTree_prediction = final_prediction\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a58d6f2-1dd3-4c43-8914-a6acee144666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of best Logistic, Linear and Decision Tree Classifiers\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8226299694189603\n",
      "Precision:  0.46923076923076923\n",
      "recall:  0.3674698795180723\n",
      "f1_score:  0.41216216216216217\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ensemble_prediction = [linear_prediction, logistic_prediction, decisionTree_prediction]\n",
    "ensemble_prediction = [sum(x) for x in zip(*ensemble_prediction)]\n",
    "final_prediction = []\n",
    "for ens in ensemble_prediction:\n",
    "    if ens >1:\n",
    "        final_prediction.append(1)\n",
    "    else:\n",
    "        final_prediction.append(0)\n",
    "\n",
    "model_desc.append([\n",
    "    \"Ensemble Logistic+Linear+Decision Tree\",\n",
    "    accuracy_score(y_test, final_prediction),\n",
    "    precision_score(y_test, final_prediction),\n",
    "    recall_score(y_test, final_prediction),\n",
    "    f1_score(y_test, final_prediction)\n",
    "                      ])        \n",
    "        \n",
    "\n",
    "print(f\"Ensemble of best Logistic, Linear and Decision Tree Classifiers\")\n",
    "print('--------------------------------------------')\n",
    "print(\"Accuracy:\", accuracy_score(y_test, final_prediction))\n",
    "print(\"Precision: \", precision_score(y_test, final_prediction))\n",
    "print(\"recall: \", recall_score(y_test, final_prediction))\n",
    "print(\"f1_score: \", f1_score(y_test, final_prediction))\n",
    "print('--------------------------------------------')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b0b986e-cc41-4549-8e05-fbd2e25966c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear Regression Ensemble</td>\n",
       "      <td>0.785423</td>\n",
       "      <td>0.387342</td>\n",
       "      <td>0.460843</td>\n",
       "      <td>0.420908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic Regression Ensemble</td>\n",
       "      <td>0.843017</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.195783</td>\n",
       "      <td>0.296804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear Regression Ensemble</td>\n",
       "      <td>0.778797</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.408719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble Logistic+Linear+Decision Tree</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.412162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  accuracy  precision    recall  \\\n",
       "0              linear Regression Ensemble  0.785423   0.387342  0.460843   \n",
       "1            logistic Regression Ensemble  0.843017   0.613208  0.195783   \n",
       "2              linear Regression Ensemble  0.778797   0.373134  0.451807   \n",
       "3  Ensemble Logistic+Linear+Decision Tree  0.822630   0.469231  0.367470   \n",
       "\n",
       "   F1 score  \n",
       "0  0.420908  \n",
       "1  0.296804  \n",
       "2  0.408719  \n",
       "3  0.412162  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_desc\n",
    "model_comparison_DF = pd.DataFrame(model_desc, columns=['model', 'accuracy', 'precision', 'recall', 'F1 score'])\n",
    "model_comparison_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684c870-4973-4273-a898-cf747cccbcd9",
   "metadata": {},
   "source": [
    "Looking at the dataframe below, It appears that the ensembled models\\\n",
    "have ea tendency to label and mislabel in a similar manner.\n",
    "most guessed labels appears to have 2 or more votes, and although this sometimes\n",
    "captures the dod, it also equally misses these labels in a ratio to 3:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49d784c4-659c-4200-941e-39ae3287330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guessed label</th>\n",
       "      <th>actual label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8403</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      guessed label  actual label\n",
       "8403              3             0\n",
       "8207              0             0\n",
       "1333              3             1\n",
       "6758              0             0\n",
       "4936              2             0\n",
       "...             ...           ...\n",
       "3081              0             0\n",
       "8008              1             0\n",
       "7674              0             1\n",
       "9641              0             0\n",
       "3527              0             0\n",
       "\n",
       "[1962 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_comparison = pd.DataFrame(\n",
    "    {'guessed label': ensemble_prediction,\n",
    "     'actual label': y_test,\n",
    "    })\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "prediction_comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
