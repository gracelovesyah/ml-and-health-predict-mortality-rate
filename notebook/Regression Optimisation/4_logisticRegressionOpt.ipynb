{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2cdcf3-d851-48b3-a494-e3acb82c347e",
   "metadata": {},
   "source": [
    "by wedad\\\n",
    "Hey team this file contains the optimisation for logistic Regression Optimzation and experimentations\\\n",
    "I'll be comparing them to the baseline model found in baseline_model.ipynb\\\n",
    "The columns dropped are selected from '4_FeatureEngineeringRegression' file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0580b4-6431-454c-ab58-f0f0fcec1b18",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LogisticRegression Optimisation\n",
    "Approaches I took were feature selection, Hyperparam tuning, Different logistic Model testing\\\n",
    "And Ensemble of different models\\\n",
    "Overall the best performing model was the Ensemble with reduced feature set, as see below:\n",
    "--------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30789322-191e-424d-bbc9-240b97f5cc36",
   "metadata": {},
   "source": [
    "Read in all the relevant Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a768fd-7d3d-4067-94cf-2bbb6bb808bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bfa9c8-c958-448b-ac70-83766a42e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb6776-994b-4027-8fad-fec112489575",
   "metadata": {},
   "source": [
    "Read In the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889d70c9-eae2-450c-8317-332806946ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>142.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>144.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>153.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9806</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>141.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9807</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>141.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9808</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9809 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dod  gender  age  Albumin  Creatinine  Hemoglobin  INR(PT)    PT  \\\n",
       "0       0       1   73      3.6         1.2         9.4      3.2  13.8   \n",
       "1       0       0   24      4.1         0.5        10.2      1.2  15.7   \n",
       "2       0       0   54      4.1         0.4        10.2      1.0  14.4   \n",
       "3       0       1   84      3.5         1.1        10.2      1.6  18.7   \n",
       "4       0       0   59      3.6         0.6        10.2      1.7  12.4   \n",
       "...   ...     ...  ...      ...         ...         ...      ...   ...   \n",
       "9804    0       1   61      3.3         3.6        10.2      1.5  13.1   \n",
       "9805    0       1   74      3.5         0.6        10.2      1.2  13.6   \n",
       "9806    0       1   58      4.1         0.6        10.2      0.9   9.3   \n",
       "9807    1       1   84      4.0         3.4        12.2      1.1  17.9   \n",
       "9808    0       1   56      3.2         6.9        10.2      1.3  25.9   \n",
       "\n",
       "      Sodium  Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "0      138.0           16.0                               48.0   \n",
       "1      143.0            6.0                               56.0   \n",
       "2      142.0           22.0                               48.0   \n",
       "3      144.0           17.0                               56.0   \n",
       "4      153.0            8.0                               70.0   \n",
       "...      ...            ...                                ...   \n",
       "9804   138.0           23.0                               62.0   \n",
       "9805   138.0            6.0                               56.0   \n",
       "9806   141.0            8.0                               56.0   \n",
       "9807   141.0           88.0                               56.0   \n",
       "9808   137.0           43.0                               56.0   \n",
       "\n",
       "      Arterial Blood Pressure systolic  Heart Rate  Respiratory Rate  \\\n",
       "0                                101.0        84.0              20.0   \n",
       "1                                114.0        59.0              16.0   \n",
       "2                                130.0        59.0              24.0   \n",
       "3                                114.0        89.0              21.0   \n",
       "4                                 91.0        99.0              21.0   \n",
       "...                                ...         ...               ...   \n",
       "9804                             103.0        89.0              20.0   \n",
       "9805                             114.0       107.0              22.0   \n",
       "9806                             114.0        78.0              10.0   \n",
       "9807                             114.0       101.0              25.0   \n",
       "9808                             114.0        88.0              19.0   \n",
       "\n",
       "      hypertension  chronic_kidney_disease  sepsis  Intercept  \n",
       "0                1                       0       0          1  \n",
       "1                0                       0       0          1  \n",
       "2                1                       0       0          1  \n",
       "3                1                       0       0          1  \n",
       "4                1                       0       1          1  \n",
       "...            ...                     ...     ...        ...  \n",
       "9804             0                       1       0          1  \n",
       "9805             1                       0       0          1  \n",
       "9806             0                       0       0          1  \n",
       "9807             1                       1       0          1  \n",
       "9808             0                       0       0          1  \n",
       "\n",
       "[9809 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aki_df = pd.read_csv('../../data/df_final_AKI.csv')\n",
    "aki_df = aki_df.drop(columns=['Unnamed: 0', 'subject_id'])\n",
    "aki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6415bc-0747-4b3c-b5f7-859f5f41955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, accuracy, precision, recall, F1 score]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_desc = []\n",
    "model_comparison_DF = pd.DataFrame(model_desc, columns=['model', 'accuracy', 'precision', 'recall', 'F1 score'])\n",
    "model_comparison_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81cb7cf-0b8f-43c1-b1ca-a2628d2565ce",
   "metadata": {},
   "source": [
    "The function below takes in different Linear Models, and tests them over number of different Seeds to get an Average perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eacb259-73c3-486a-9833-38ce173e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = aki_df.drop(columns=['dod'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "def logisticTester(model_desc, model, x, y, title='alg', printer=False):\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    for rand in seed_list:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y, test_size=0.25, random_state=rand)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred_log = model.predict(x_test)\n",
    "        total_acc += accuracy_score(y_test, y_pred_log)\n",
    "        total_pre += precision_score(y_test, y_pred_log)\n",
    "        total_rec += recall_score(y_test, y_pred_log)\n",
    "        total_f1 += f1_score(y_test, y_pred_log)\n",
    "\n",
    "    model_desc.append([\n",
    "        title,\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "        \n",
    "                      ])\n",
    "    if printer:\n",
    "        # Evaluate\n",
    "        print(f\"{title}\")\n",
    "        print('--------------------------------------------')\n",
    "        print(\"Accuracy:\", total_acc/total,)\n",
    "        print(\"Precision: \", total_pre/total,)\n",
    "        print(\"recall: \", total_rec/total,)\n",
    "        print(\"f1_score: \", total_f1/total,)\n",
    "        print('--------------------------------------------')\n",
    "        # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2195457e-26b2-4e3f-acc6-e34b6ce6b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "logisticTester(model_desc, log_reg, x, y,'Logistic Regression baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19b7d5-7d78-40b1-9d83-3d62dfb0ebc6",
   "metadata": {},
   "source": [
    "Baseline model, accuracy of approximately 0.844\\\n",
    "It is important that due to the imbalance\\ \n",
    "Predicting every value to be 0 gives 83% accuracy\\\n",
    "In our case, it is important that we focus on Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ea23c5-3693-424a-bfe9-4be74d37fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = aki_df.drop(columns=['dod','Sodium','Hemoglobin','gender','hypertension','Intercept'])\n",
    "y = aki_df['dod']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y, test_size=0.25, random_state=seed_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddb9665-13fc-4c73-b51e-347f606dea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticTester(model_desc, log_reg, x, y,'Logistic Regression modified Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d8e55-4d89-4adc-8e8d-6b47f52084f0",
   "metadata": {},
   "source": [
    "Baseline model reduced feature, accuracy of approximately 0.846\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4ae355-e1d9-470f-869f-85e5c4c5316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 20 mins to run this code below\n",
      "------------L2 and None Penalty -------------\n",
      "It takes 6 mins to run this code below\n",
      "------------L1 Penalty -------------\n",
      "It takes 3 mins to run this code below\n",
      "------------elasticnet Penalty -------------\n"
     ]
    }
   ],
   "source": [
    "# ‘lbfgs’ - [‘l2’, None]\n",
    "# ‘newton-cholesky’ - [‘l2’, None]\n",
    "# ‘newton-cg’ - [‘l2’, None]\n",
    "# ‘sag’ - [‘l2’, None]\n",
    "# ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "# ‘liblinear’ - [‘l1’, ‘l2’]\n",
    "# ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "\n",
    "c_val = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]  # Regularization strength\n",
    "c_weight = [None, 'balanced']\n",
    "\n",
    "\n",
    "\n",
    "print(\"It takes 10 mins to run this code below\")\n",
    "# f1_score max | model -> lbfg C:0.0001 weight: balanced penalty: l2 | Accuracy: precision: 0.713168 0.329235 Recall: 0.669157 F1 Score: 0.441194\n",
    "# Accuracy max | model -> sag C:10 weight: None penalty: None | Accuracy: 0.845862  precision: 0.679856  Recall: 0.169157 F1 Score: 0.270599\n",
    "\n",
    "print(\"------------L2 and None Penalty -------------\")\n",
    "penalty_list = ['l2', None]\n",
    "\n",
    "for c in c_val:\n",
    "    for weight in c_weight:\n",
    "        for pen in penalty_list:\n",
    "            log_lbgfs = LogisticRegression(penalty=pen, solver= 'lbfgs', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'lbfg C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_lbgfs, x, y, title, printer=False)\n",
    "            \n",
    "            log_n_chol = LogisticRegression(penalty=pen, solver= 'newton-cholesky', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'newton-cholesky C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_n_chol, x, y, title, printer=False)\n",
    "            \n",
    "            log_n_cg = LogisticRegression(penalty=pen, solver= 'newton-cg', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'log_n_cg C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_n_cg, x, y, title, printer=False)\n",
    "            \n",
    "            log_sag = LogisticRegression(penalty=pen, solver= 'sag', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'sag C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_sag, x, y, title, printer=False)\n",
    "            \n",
    "            log_saga = LogisticRegression(penalty=pen, solver= 'saga', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'saga C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_saga, x, y, title, printer=False)\n",
    "            \n",
    "print(\"It takes 6 mins to run this code below\")            \n",
    "print(\"------------L1 Penalty -------------\")\n",
    "penalty_list = ['l1']\n",
    "\n",
    "for c in c_val:\n",
    "    for weight in c_weight:\n",
    "        for pen in penalty_list:\n",
    "            log_liblinear = LogisticRegression(penalty=pen, solver= 'liblinear', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'liblinear C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_liblinear, x, y, title, printer=False)\n",
    "            \n",
    "            log_saga = LogisticRegression(penalty=pen, solver= 'saga', class_weight = weight, max_iter=1000, C=c)\n",
    "            title = f'saga C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_saga, x, y, title, printer=False)\n",
    "\n",
    "print(\"It takes 3 mins to run this code below\")\n",
    "print(\"------------elasticnet Penalty -------------\")\n",
    "penalty_list = ['elasticnet']\n",
    "\n",
    "for c in c_val:\n",
    "    for weight in c_weight:\n",
    "        for pen in penalty_list:   \n",
    "            log_saga = LogisticRegression(penalty=pen, solver= 'saga', class_weight = weight, max_iter=1000, C=c, l1_ratio=0.5)\n",
    "            title = f'saga C:{c} weight: {weight} penalty: {pen}'\n",
    "            logisticTester(model_desc, log_saga, x, y, title, printer=False)\n",
    "            \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d495b4-639f-4c1d-b346-735f1c1215c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression baseline</td>\n",
       "      <td>0.844109</td>\n",
       "      <td>0.655321</td>\n",
       "      <td>0.166988</td>\n",
       "      <td>0.265826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression modified Features</td>\n",
       "      <td>0.845577</td>\n",
       "      <td>0.673793</td>\n",
       "      <td>0.170361</td>\n",
       "      <td>0.271598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbfg C:0.0001 weight: None penalty: l2</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.707442</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.159130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newton-cholesky C:0.0001 weight: None penalty: l2</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.707442</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.159130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log_n_cg C:0.0001 weight: None penalty: l2</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.707442</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.159130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>saga C:1 weight: balanced penalty: elasticnet</td>\n",
       "      <td>0.711741</td>\n",
       "      <td>0.327431</td>\n",
       "      <td>0.666988</td>\n",
       "      <td>0.439134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>saga C:10 weight: None penalty: elasticnet</td>\n",
       "      <td>0.845618</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.264540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>saga C:10 weight: balanced penalty: elasticnet</td>\n",
       "      <td>0.711863</td>\n",
       "      <td>0.327594</td>\n",
       "      <td>0.667229</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>saga C:100 weight: None penalty: elasticnet</td>\n",
       "      <td>0.845618</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.264540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>saga C:100 weight: balanced penalty: elasticnet</td>\n",
       "      <td>0.711863</td>\n",
       "      <td>0.327594</td>\n",
       "      <td>0.667229</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  accuracy  precision  \\\n",
       "0                         Logistic Regression baseline  0.844109   0.655321   \n",
       "1                Logistic Regression modified Features  0.845577   0.673793   \n",
       "2               lbfg C:0.0001 weight: None penalty: l2  0.839503   0.707442   \n",
       "3    newton-cholesky C:0.0001 weight: None penalty: l2  0.839503   0.707442   \n",
       "4           log_n_cg C:0.0001 weight: None penalty: l2  0.839503   0.707442   \n",
       "..                                                 ...       ...        ...   \n",
       "179      saga C:1 weight: balanced penalty: elasticnet  0.711741   0.327431   \n",
       "180         saga C:10 weight: None penalty: elasticnet  0.845618   0.681981   \n",
       "181     saga C:10 weight: balanced penalty: elasticnet  0.711863   0.327594   \n",
       "182        saga C:100 weight: None penalty: elasticnet  0.845618   0.681981   \n",
       "183    saga C:100 weight: balanced penalty: elasticnet  0.711863   0.327594   \n",
       "\n",
       "       recall  F1 score  \n",
       "0    0.166988  0.265826  \n",
       "1    0.170361  0.271598  \n",
       "2    0.089880  0.159130  \n",
       "3    0.089880  0.159130  \n",
       "4    0.089880  0.159130  \n",
       "..        ...       ...  \n",
       "179  0.666988  0.439134  \n",
       "180  0.164337  0.264540  \n",
       "181  0.667229  0.439336  \n",
       "182  0.164337  0.264540  \n",
       "183  0.667229  0.439336  \n",
       "\n",
       "[184 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_DF = pd.DataFrame(model_desc, columns=['model', 'accuracy', 'precision', 'recall', 'F1 score'])\n",
    "model_comparison_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00bb56fa-f320-46c7-bdbc-a975e7b04012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>lbfg C:0.1 weight: balanced penalty: l2</td>\n",
       "      <td>0.713861</td>\n",
       "      <td>0.329974</td>\n",
       "      <td>0.669639</td>\n",
       "      <td>0.441970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>newton-cholesky C:0.1 weight: balanced penalty...</td>\n",
       "      <td>0.713942</td>\n",
       "      <td>0.330014</td>\n",
       "      <td>0.669398</td>\n",
       "      <td>0.441949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  accuracy  precision  \\\n",
       "72            lbfg C:0.1 weight: balanced penalty: l2  0.713861   0.329974   \n",
       "73  newton-cholesky C:0.1 weight: balanced penalty...  0.713942   0.330014   \n",
       "\n",
       "      recall  F1 score  \n",
       "72  0.669639  0.441970  \n",
       "73  0.669398  0.441949  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_DF.sort_values(by=['F1 score'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad401083-0c2c-4fe5-947f-df414811f015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>liblinear C:0.1 weight: None penalty: l1</td>\n",
       "      <td>0.846433</td>\n",
       "      <td>0.695005</td>\n",
       "      <td>0.165301</td>\n",
       "      <td>0.266840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>sag C:0.1 weight: None penalty: l2</td>\n",
       "      <td>0.846311</td>\n",
       "      <td>0.689264</td>\n",
       "      <td>0.167470</td>\n",
       "      <td>0.269204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model  accuracy  precision    recall  \\\n",
       "154  liblinear C:0.1 weight: None penalty: l1  0.846433   0.695005  0.165301   \n",
       "65         sag C:0.1 weight: None penalty: l2  0.846311   0.689264  0.167470   \n",
       "\n",
       "     F1 score  \n",
       "154  0.266840  \n",
       "65   0.269204  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_DF.sort_values(by=['accuracy'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1dde241-1492-440e-955a-9ac479ce3377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>saga C:0.001 weight: None penalty: l2</td>\n",
       "      <td>0.844476</td>\n",
       "      <td>0.772868</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.200306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sag C:0.001 weight: None penalty: l2</td>\n",
       "      <td>0.844476</td>\n",
       "      <td>0.772868</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.200306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  accuracy  precision    recall  \\\n",
       "26  saga C:0.001 weight: None penalty: l2  0.844476   0.772868  0.115181   \n",
       "25   sag C:0.001 weight: None penalty: l2  0.844476   0.772868  0.115181   \n",
       "\n",
       "    F1 score  \n",
       "26  0.200306  \n",
       "25  0.200306  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_DF.sort_values(by=['precision'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec17bed4-f6f4-473d-9e70-126c5e5e1899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>lbfg C:0.1 weight: balanced penalty: l2</td>\n",
       "      <td>0.713861</td>\n",
       "      <td>0.329974</td>\n",
       "      <td>0.669639</td>\n",
       "      <td>0.441970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>lbfg C:10 weight: balanced penalty: l2</td>\n",
       "      <td>0.713127</td>\n",
       "      <td>0.329256</td>\n",
       "      <td>0.669398</td>\n",
       "      <td>0.441254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  accuracy  precision    recall  \\\n",
       "72   lbfg C:0.1 weight: balanced penalty: l2  0.713861   0.329974  0.669639   \n",
       "112   lbfg C:10 weight: balanced penalty: l2  0.713127   0.329256  0.669398   \n",
       "\n",
       "     F1 score  \n",
       "72   0.441970  \n",
       "112  0.441254  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_DF.sort_values(by=['recall'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41402f-f724-4a91-81cc-afc8862d4c0b",
   "metadata": {},
   "source": [
    "Ensemble of 4 best performing modesl for Accuracym Precision, Recall and F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d38e5f-cd05-4212-a4d1-b4c038514dcc",
   "metadata": {},
   "source": [
    "Description | Model | Accuracy | Precision | Recall | F1 Score\\\n",
    "best f1: lbfg C:0.1 weight: balanced penalty: l2\t0.713861\t0.329974\t0.669639\t0.441970\\\n",
    "best accuracy: liblinear C:0.1 weight: None penalty: l1\t0.846433\t0.695005\t0.165301\t0.266840\\\n",
    "best precision: saga C:0.001 weight: None penalty: l2\t0.844476\t0.772868\t0.115181\t0.200306\\\n",
    "brest recall: lbfg C:0.1 weight: balanced penalty: l2\t0.713861\t0.329974\t0.669639\t0.441970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "248b29df-9988-4f1f-99a7-2ad488d7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticEnsemble(model_list, model_desc, x, y, title='Combined Ensemble'):\n",
    "    prediction_list = []\n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "    for rand in seed_list:\n",
    "        prediction_list = []\n",
    "        for model in model_list:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y, test_size=0.25, random_state=rand)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred_log = model.predict(x_test)\n",
    "            prediction_list.append(y_pred_log)\n",
    "\n",
    "        prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "        final_prediction = []\n",
    "        for pred in prediction_list:\n",
    "            if pred >1:\n",
    "                final_prediction.append(1)\n",
    "            else:\n",
    "                final_prediction.append(0)\n",
    "                \n",
    "        total_acc += accuracy_score(y_test, final_prediction)\n",
    "        total_pre += precision_score(y_test, final_prediction)\n",
    "        total_rec += recall_score(y_test, final_prediction)\n",
    "        total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "\n",
    "    model_desc.append([\n",
    "        \"logistic Regression Ensemble\",\n",
    "        total_acc/total,\n",
    "        total_pre/total,\n",
    "        total_rec/total,\n",
    "        total_f1/total\n",
    "                      ])\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"{title}\")\n",
    "    print('--------------------------------------------')\n",
    "    print(\"Accuracy:\", total_acc/total)\n",
    "    print(\"Precision: \", total_pre/total)\n",
    "    print(\"recall: \", total_rec/total)\n",
    "    print(\"f1_score: \", total_f1/total)\n",
    "    print('--------------------------------------------')\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d1c2232-fee5-4dcd-8497-d3856184a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Feature Set Logistic Combined Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8473298002445985\n",
      "Precision:  0.6938018224153757\n",
      "recall:  0.17590361445783131\n",
      "f1_score:  0.28038677574593573\n",
      "--------------------------------------------\n",
      "Full Feature Set Logistic Combined Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8465552384834896\n",
      "Precision:  0.6756449129175457\n",
      "recall:  0.17951807228915664\n",
      "f1_score:  0.28345060616105877\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = aki_df.drop(columns=['dod','Sodium','Hemoglobin','gender','hypertension','Intercept'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "log_lbgfs = LogisticRegression(penalty='l2', solver= 'lbfgs', class_weight = 'balanced', max_iter=1000, C=0.1)\n",
    "log_liblinear = LogisticRegression(penalty='l1', solver= 'liblinear', class_weight = None, max_iter=1000, C=0.1)\n",
    "log_saga = LogisticRegression(penalty='l2', solver= 'saga', class_weight = None, max_iter=1000, C=0.001)\n",
    "\n",
    "model_list = [log_lbgfs, log_liblinear, log_saga]\n",
    "\n",
    "logisticEnsemble(model_list, model_desc, x, y, title='Reduced Feature Set Logistic Combined Ensemble')\n",
    "\n",
    "\n",
    "x = aki_df.drop(columns=['dod'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "logisticEnsemble(model_list, model_desc, x, y, title='Full Feature Set Logistic Combined Ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943af2c7-76ee-4102-8f74-4cc9b4ad8050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aec30369-f432-4de0-802d-5ab6db0b934c",
   "metadata": {},
   "source": [
    "## Sampling Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21ca9ccf-26a6-4965-a936-f6c342628c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16f1c661-0700-4743-a072-b2c15da928b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = aki_df.drop(columns=['dod', 'Sodium','Hemoglobin','gender','hypertension','Intercept'])\n",
    "y = aki_df['dod']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=0)\n",
    "# Define models for each approach\n",
    "models = [log_lbgfs, log_liblinear, log_saga]\n",
    "# Define sampling methods\n",
    "sampling_methods = [None,  RandomOverSampler(),  SMOTE(), ADASYN(),RandomUnderSampler(), SMOTEENN(), SMOTETomek(), NearMiss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64976a98-22e3-4535-912b-837f6cd2196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate models\n",
    "def resampled_eval(model, x_train, y_train, x_test, y_test, sampling_method, seed_list, model_desc, printer = False):\n",
    "    \n",
    "    total_acc = 0\n",
    "    total_pre = 0\n",
    "    total_rec = 0\n",
    "    total_f1 = 0\n",
    "    total = len(seed_list)\n",
    "    \n",
    "    for j in seed_list:\n",
    "        if sampling_method:\n",
    "            x_train_resampled, y_train_resampled = sampling_method.fit_resample(x_train, y_train)\n",
    "        else:\n",
    "            x_train_resampled = x_train\n",
    "            y_train_resampled = y_train\n",
    "            \n",
    "        model.fit(x_train_resampled, y_train_resampled)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Evaluate\n",
    "        total_acc += accuracy_score(y_test, y_pred)\n",
    "        total_pre += precision_score(y_test, y_pred)\n",
    "        total_rec += recall_score(y_test, y_pred)\n",
    "        total_f1 += f1_score(y_test, y_pred)\n",
    "        \n",
    "        \n",
    "    model_desc.append([\n",
    "    str(sampling_method) + str(model),\n",
    "    total_acc/total,\n",
    "    total_pre/total,\n",
    "    total_rec/total,\n",
    "    total_f1/total\n",
    "    ])\n",
    "        \n",
    "    if printer:\n",
    "        print(f\"{str(sampling_method)}\")\n",
    "        print('--------------------------------------------')\n",
    "        print(\"Accuracy:\", total_acc/total,)\n",
    "        print(\"Precision: \", total_pre/total,)\n",
    "        print(\"recall: \", total_rec/total,)\n",
    "        print(\"f1_score: \", total_f1/total,)\n",
    "        print('--------------------------------------------')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc618251-4720-4e96-b47a-79b557f7bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Methods for logistic Regressions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoneLogisticRegression(C=0.1, class_weight='ba...</td>\n",
       "      <td>0.715087</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.443781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoneLogisticRegression(C=0.1, max_iter=1000, p...</td>\n",
       "      <td>0.845566</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.296984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoneLogisticRegression(C=0.001, max_iter=1000,...</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.211055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomOverSampler()LogisticRegression(C=0.1, c...</td>\n",
       "      <td>0.713201</td>\n",
       "      <td>0.329092</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.441159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomOverSampler()LogisticRegression(C=0.1, m...</td>\n",
       "      <td>0.712895</td>\n",
       "      <td>0.329250</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.441890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomOverSampler()LogisticRegression(C=0.001,...</td>\n",
       "      <td>0.707034</td>\n",
       "      <td>0.320202</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>0.429305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE()LogisticRegression(C=0.1, class_weight=...</td>\n",
       "      <td>0.719113</td>\n",
       "      <td>0.319388</td>\n",
       "      <td>0.583434</td>\n",
       "      <td>0.412796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE()LogisticRegression(C=0.1, max_iter=1000...</td>\n",
       "      <td>0.717278</td>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.585241</td>\n",
       "      <td>0.411957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE()LogisticRegression(C=0.001, max_iter=10...</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>0.636145</td>\n",
       "      <td>0.430491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADASYN()LogisticRegression(C=0.1, class_weight...</td>\n",
       "      <td>0.705148</td>\n",
       "      <td>0.310066</td>\n",
       "      <td>0.606024</td>\n",
       "      <td>0.410235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADASYN()LogisticRegression(C=0.1, max_iter=100...</td>\n",
       "      <td>0.714424</td>\n",
       "      <td>0.316635</td>\n",
       "      <td>0.593675</td>\n",
       "      <td>0.412996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADASYN()LogisticRegression(C=0.001, max_iter=1...</td>\n",
       "      <td>0.711213</td>\n",
       "      <td>0.323025</td>\n",
       "      <td>0.644880</td>\n",
       "      <td>0.430439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler()LogisticRegression(C=0.1, ...</td>\n",
       "      <td>0.711774</td>\n",
       "      <td>0.328211</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.440939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler()LogisticRegression(C=0.1, ...</td>\n",
       "      <td>0.709939</td>\n",
       "      <td>0.325646</td>\n",
       "      <td>0.666566</td>\n",
       "      <td>0.437511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler()LogisticRegression(C=0.001...</td>\n",
       "      <td>0.693119</td>\n",
       "      <td>0.305909</td>\n",
       "      <td>0.640964</td>\n",
       "      <td>0.414145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMOTEENN()LogisticRegression(C=0.1, class_weig...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.311053</td>\n",
       "      <td>0.636145</td>\n",
       "      <td>0.417806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTEENN()LogisticRegression(C=0.1, max_iter=1...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.269958</td>\n",
       "      <td>0.723193</td>\n",
       "      <td>0.393149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTEENN()LogisticRegression(C=0.001, max_iter...</td>\n",
       "      <td>0.571101</td>\n",
       "      <td>0.252432</td>\n",
       "      <td>0.782229</td>\n",
       "      <td>0.381682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SMOTETomek()LogisticRegression(C=0.1, class_we...</td>\n",
       "      <td>0.719368</td>\n",
       "      <td>0.319429</td>\n",
       "      <td>0.582229</td>\n",
       "      <td>0.412523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMOTETomek()LogisticRegression(C=0.1, max_iter...</td>\n",
       "      <td>0.717992</td>\n",
       "      <td>0.318941</td>\n",
       "      <td>0.587048</td>\n",
       "      <td>0.413313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SMOTETomek()LogisticRegression(C=0.001, max_it...</td>\n",
       "      <td>0.714577</td>\n",
       "      <td>0.324841</td>\n",
       "      <td>0.636747</td>\n",
       "      <td>0.430203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NearMiss()LogisticRegression(C=0.1, class_weig...</td>\n",
       "      <td>0.634047</td>\n",
       "      <td>0.271327</td>\n",
       "      <td>0.689759</td>\n",
       "      <td>0.389456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NearMiss()LogisticRegression(C=0.1, max_iter=1...</td>\n",
       "      <td>0.630989</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.382253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NearMiss()LogisticRegression(C=0.001, max_iter...</td>\n",
       "      <td>0.609072</td>\n",
       "      <td>0.251429</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.364540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  accuracy  precision  \\\n",
       "0   NoneLogisticRegression(C=0.1, class_weight='ba...  0.715087   0.331352   \n",
       "1   NoneLogisticRegression(C=0.1, max_iter=1000, p...  0.845566   0.646465   \n",
       "2   NoneLogisticRegression(C=0.001, max_iter=1000,...  0.839959   0.636364   \n",
       "3   RandomOverSampler()LogisticRegression(C=0.1, c...  0.713201   0.329092   \n",
       "4   RandomOverSampler()LogisticRegression(C=0.1, m...  0.712895   0.329250   \n",
       "5   RandomOverSampler()LogisticRegression(C=0.001,...  0.707034   0.320202   \n",
       "6   SMOTE()LogisticRegression(C=0.1, class_weight=...  0.719113   0.319388   \n",
       "7   SMOTE()LogisticRegression(C=0.1, max_iter=1000...  0.717278   0.317852   \n",
       "8   SMOTE()LogisticRegression(C=0.001, max_iter=10...  0.715189   0.325325   \n",
       "9   ADASYN()LogisticRegression(C=0.1, class_weight...  0.705148   0.310066   \n",
       "10  ADASYN()LogisticRegression(C=0.1, max_iter=100...  0.714424   0.316635   \n",
       "11  ADASYN()LogisticRegression(C=0.001, max_iter=1...  0.711213   0.323025   \n",
       "12  RandomUnderSampler()LogisticRegression(C=0.1, ...  0.711774   0.328211   \n",
       "13  RandomUnderSampler()LogisticRegression(C=0.1, ...  0.709939   0.325646   \n",
       "14  RandomUnderSampler()LogisticRegression(C=0.001...  0.693119   0.305909   \n",
       "15  SMOTEENN()LogisticRegression(C=0.1, class_weig...  0.700000   0.311053   \n",
       "16  SMOTEENN()LogisticRegression(C=0.1, max_iter=1...  0.622222   0.269958   \n",
       "17  SMOTEENN()LogisticRegression(C=0.001, max_iter...  0.571101   0.252432   \n",
       "18  SMOTETomek()LogisticRegression(C=0.1, class_we...  0.719368   0.319429   \n",
       "19  SMOTETomek()LogisticRegression(C=0.1, max_iter...  0.717992   0.318941   \n",
       "20  SMOTETomek()LogisticRegression(C=0.001, max_it...  0.714577   0.324841   \n",
       "21  NearMiss()LogisticRegression(C=0.1, class_weig...  0.634047   0.271327   \n",
       "22  NearMiss()LogisticRegression(C=0.1, max_iter=1...  0.630989   0.266667   \n",
       "23  NearMiss()LogisticRegression(C=0.001, max_iter...  0.609072   0.251429   \n",
       "\n",
       "      recall  F1 score  \n",
       "0   0.671687  0.443781  \n",
       "1   0.192771  0.296984  \n",
       "2   0.126506  0.211055  \n",
       "3   0.668976  0.441159  \n",
       "4   0.671687  0.441890  \n",
       "5   0.651205  0.429305  \n",
       "6   0.583434  0.412796  \n",
       "7   0.585241  0.411957  \n",
       "8   0.636145  0.430491  \n",
       "9   0.606024  0.410235  \n",
       "10  0.593675  0.412996  \n",
       "11  0.644880  0.430439  \n",
       "12  0.671687  0.440939  \n",
       "13  0.666566  0.437511  \n",
       "14  0.640964  0.414145  \n",
       "15  0.636145  0.417806  \n",
       "16  0.723193  0.393149  \n",
       "17  0.782229  0.381682  \n",
       "18  0.582229  0.412523  \n",
       "19  0.587048  0.413313  \n",
       "20  0.636747  0.430203  \n",
       "21  0.689759  0.389456  \n",
       "22  0.674699  0.382253  \n",
       "23  0.662651  0.364540  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sampling Methods for logistic Regressions\")\n",
    "sampling_desc = []\n",
    "for samp in sampling_methods:\n",
    "    for mod in models:\n",
    "        resampled_eval(mod, x_train, y_train, x_test, y_test, samp, seed_list, sampling_desc)\n",
    "    \n",
    "sample_comparison_DF = pd.DataFrame(sampling_desc, columns=['model', 'accuracy', 'precision', 'recall', 'F1 score'])\n",
    "sample_comparison_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6b82968-6aae-41eb-af03-286ef1b56f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoneLogisticRegression(C=0.1, class_weight='ba...</td>\n",
       "      <td>0.715087</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.443781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomOverSampler()LogisticRegression(C=0.1, m...</td>\n",
       "      <td>0.712895</td>\n",
       "      <td>0.329250</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.441890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  precision  \\\n",
       "0  NoneLogisticRegression(C=0.1, class_weight='ba...  0.715087   0.331352   \n",
       "4  RandomOverSampler()LogisticRegression(C=0.1, m...  0.712895   0.329250   \n",
       "\n",
       "     recall  F1 score  \n",
       "0  0.671687  0.443781  \n",
       "4  0.671687  0.441890  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comparison_DF.sort_values(by=['F1 score'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b616516-1ba1-406b-a62e-1ca1ae831622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoneLogisticRegression(C=0.1, max_iter=1000, p...</td>\n",
       "      <td>0.845566</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.296984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoneLogisticRegression(C=0.001, max_iter=1000,...</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.211055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  precision  \\\n",
       "1  NoneLogisticRegression(C=0.1, max_iter=1000, p...  0.845566   0.646465   \n",
       "2  NoneLogisticRegression(C=0.001, max_iter=1000,...  0.839959   0.636364   \n",
       "\n",
       "     recall  F1 score  \n",
       "1  0.192771  0.296984  \n",
       "2  0.126506  0.211055  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comparison_DF.sort_values(by=['accuracy'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5895cca5-b463-4a6a-98b8-03eb64552960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoneLogisticRegression(C=0.1, max_iter=1000, p...</td>\n",
       "      <td>0.845566</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.296984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoneLogisticRegression(C=0.001, max_iter=1000,...</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.211055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  precision  \\\n",
       "1  NoneLogisticRegression(C=0.1, max_iter=1000, p...  0.845566   0.646465   \n",
       "2  NoneLogisticRegression(C=0.001, max_iter=1000,...  0.839959   0.636364   \n",
       "\n",
       "     recall  F1 score  \n",
       "1  0.192771  0.296984  \n",
       "2  0.126506  0.211055  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comparison_DF.sort_values(by=['precision'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f5f927c-08f2-472e-977e-f7f04f246276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTEENN()LogisticRegression(C=0.001, max_iter...</td>\n",
       "      <td>0.571101</td>\n",
       "      <td>0.252432</td>\n",
       "      <td>0.782229</td>\n",
       "      <td>0.381682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTEENN()LogisticRegression(C=0.1, max_iter=1...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.269958</td>\n",
       "      <td>0.723193</td>\n",
       "      <td>0.393149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  accuracy  precision  \\\n",
       "17  SMOTEENN()LogisticRegression(C=0.001, max_iter...  0.571101   0.252432   \n",
       "16  SMOTEENN()LogisticRegression(C=0.1, max_iter=1...  0.622222   0.269958   \n",
       "\n",
       "      recall  F1 score  \n",
       "17  0.782229  0.381682  \n",
       "16  0.723193  0.393149  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comparison_DF.sort_values(by=['recall'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fe11071-e733-4676-9216-ebb2c58e0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best recall:  SMOTEENN()LogisticRegression(C=0.001, max_iter=1000, solver='saga')\n",
      "best precision:  NoneLogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n",
      "best accuracy:  NoneLogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n",
      "best F1 Score:  NoneLogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "print('best recall: ', sample_comparison_DF.sort_values(by=['recall'], ascending=False).head(1).iloc[0]['model'])\n",
    "print('best precision: ',sample_comparison_DF.sort_values(by=['precision'], ascending=False).head(1).iloc[0]['model'])\n",
    "print('best accuracy: ',sample_comparison_DF.sort_values(by=['accuracy'], ascending=False).head(1).iloc[0]['model'])\n",
    "print('best F1 Score: ',sample_comparison_DF.sort_values(by=['F1 score'], ascending=False).head(1).iloc[0]['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c621d02-0f7f-45f2-93a9-4d666f82a185",
   "metadata": {},
   "source": [
    "## Ensemble of the best resampled models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36e3140f-1e8b-4fd9-9ed8-e82eaff5e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Ensemble\n",
      "--------------------------------------------\n",
      "Accuracy: 0.8464322120285424\n",
      "Precision:  0.6950585280617547\n",
      "recall:  0.16536144578313253\n",
      "f1_score:  0.2668647661191462\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_prediction = []\n",
    "total_acc = 0\n",
    "total_pre = 0\n",
    "total_rec = 0\n",
    "total_f1 = 0\n",
    "total = len(seed_list)\n",
    "\n",
    "sampled_reg = LogisticRegression(C=0.001, max_iter=1000, solver='saga')\n",
    "precision_reg = LogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear')\n",
    "f1_reg = LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)\n",
    "    \n",
    "for rand in seed_list:\n",
    "    prediction_list = []\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y, test_size=0.2, random_state=rand)\n",
    "        \n",
    "    x_train_resampled, y_train_resampled = SMOTEENN().fit_resample(x_train, y_train)\n",
    "    sampled_reg.fit(x_train_resampled, y_train_resampled)\n",
    "        \n",
    "    precision_reg.fit(x_train, y_train)\n",
    "        \n",
    "    f1_reg.fit(x_train, y_train)\n",
    "        \n",
    "        \n",
    "    y_pred_log1 = sampled_reg.predict(x_test)\n",
    "    y_pred_log2 = precision_reg.predict(x_test)\n",
    "    y_pred_log3 = f1_reg.predict(x_test) \n",
    "\n",
    "    prediction_list.append(y_pred_log1)\n",
    "    prediction_list.append(y_pred_log2)\n",
    "    prediction_list.append(y_pred_log3)\n",
    "                \n",
    "    prediction_list = [sum(x) for x in zip(*prediction_list)]\n",
    "    # print(set(prediction_list))\n",
    "    \n",
    "    final_prediction = []\n",
    "    for pred in prediction_list:\n",
    "        if pred >2:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "                \n",
    "        # print(set(prediction_list))\n",
    "    total_acc += accuracy_score(y_test, final_prediction)\n",
    "    total_pre += precision_score(y_test, final_prediction)\n",
    "    total_rec += recall_score(y_test, final_prediction)\n",
    "    total_f1 += f1_score(y_test, final_prediction)\n",
    "\n",
    "    # Evaluate\n",
    "print(f\"Resampled Ensemble\")\n",
    "print('--------------------------------------------')\n",
    "print(\"Accuracy:\", total_acc/total)\n",
    "print(\"Precision: \", total_pre/total)\n",
    "print(\"recall: \", total_rec/total)\n",
    "print(\"f1_score: \", total_f1/total)\n",
    "print('--------------------------------------------')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
