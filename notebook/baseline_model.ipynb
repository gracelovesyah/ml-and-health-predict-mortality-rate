{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Exploration\n",
    "\n",
    "*by Grace*\n",
    "\n",
    "Hello Team,\n",
    "\n",
    "In this notebook, I've embarked on an initial exploration of various baseline models for our binary classification task. The primary goal was to establish a foundational understanding of the performance we can expect from some common algorithms, without any extensive tuning or optimisation.\n",
    "\n",
    "## Models Explored:\n",
    "- **Linear Regression**: Used as a binary classifier with a threshold.\n",
    "- **Logistic Regression**: A standard approach for binary classification tasks.\n",
    "- **Dummy Classifier**: Provides predictions based on simple rules, serving as a basic baseline.\n",
    "- **Decision Tree Classifier**: A simple and interpretable model.\n",
    "- **Random Forest Classifier**: An ensemble method using multiple decision trees.\n",
    "- **Support Vector Machine (SVM)**: Explored with a linear kernel.\n",
    "\n",
    "## Next Steps:\n",
    "- These models can serve as a starting point. There's ample room for optimisation, including hyperparameter tuning, feature engineering, and exploring more complex models.\n",
    "- It would be beneficial to delve deeper into each model's performance metrics, especially if our dataset has class imbalances.\n",
    "- Feedback and collaboration are encouraged. If anyone has insights or suggestions on improving these baseline models or wants to introduce other potential models, please share!\n",
    "\n",
    "Let's collaborate and refine our approach to achieve the best model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_final_AKI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- discover imbalance trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'subject_id', 'dod', 'gender', 'age', 'Albumin',\n",
       "       'Albumin/Creatinine, Urine', 'Creatinine', 'INR(PT)', 'PT', 'Sodium',\n",
       "       'Urea Nitrogen', 'Arterial Blood Pressure diastolic',\n",
       "       'Arterial Blood Pressure systolic', 'Heart Rate', 'HrApacheIIScore',\n",
       "       'Respiratory Rate', 'Temperature Celsius', 'hypertension',\n",
       "       'chronic_kidney_disease', 'sepsis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin/Creatinine, Urine</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>...</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>HrApacheIIScore</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>Temperature Celsius</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9.432000e+03</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>8547.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9334.000000</td>\n",
       "      <td>9316.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9428.000000</td>\n",
       "      <td>5224.000000</td>\n",
       "      <td>5223.000000</td>\n",
       "      <td>9431.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9429.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "      <td>9432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4715.500000</td>\n",
       "      <td>1.502744e+07</td>\n",
       "      <td>0.172922</td>\n",
       "      <td>0.599979</td>\n",
       "      <td>66.431298</td>\n",
       "      <td>3.451082</td>\n",
       "      <td>592.555623</td>\n",
       "      <td>1.809606</td>\n",
       "      <td>1.472087</td>\n",
       "      <td>16.207450</td>\n",
       "      <td>...</td>\n",
       "      <td>31.481438</td>\n",
       "      <td>57.653331</td>\n",
       "      <td>117.044036</td>\n",
       "      <td>85.585304</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>19.706544</td>\n",
       "      <td>36.853541</td>\n",
       "      <td>0.528626</td>\n",
       "      <td>0.380831</td>\n",
       "      <td>0.114928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2722.928203</td>\n",
       "      <td>2.897813e+06</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>0.489928</td>\n",
       "      <td>15.422978</td>\n",
       "      <td>0.759529</td>\n",
       "      <td>1752.909095</td>\n",
       "      <td>1.766590</td>\n",
       "      <td>0.775652</td>\n",
       "      <td>8.270952</td>\n",
       "      <td>...</td>\n",
       "      <td>23.381033</td>\n",
       "      <td>13.378989</td>\n",
       "      <td>23.043919</td>\n",
       "      <td>18.476666</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>5.903741</td>\n",
       "      <td>4.406911</td>\n",
       "      <td>0.499206</td>\n",
       "      <td>0.485617</td>\n",
       "      <td>0.318952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000201e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2357.750000</td>\n",
       "      <td>1.252498e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4715.500000</td>\n",
       "      <td>1.507287e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>62.900000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7073.250000</td>\n",
       "      <td>1.756267e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>320.775000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9431.000000</td>\n",
       "      <td>1.999983e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>25235.000000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>101.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    subject_id          dod       gender          age  \\\n",
       "count  9432.000000  9.432000e+03  9432.000000  9432.000000  9432.000000   \n",
       "mean   4715.500000  1.502744e+07     0.172922     0.599979    66.431298   \n",
       "std    2722.928203  2.897813e+06     0.378200     0.489928    15.422978   \n",
       "min       0.000000  1.000201e+07     0.000000     0.000000    18.000000   \n",
       "25%    2357.750000  1.252498e+07     0.000000     0.000000    57.000000   \n",
       "50%    4715.500000  1.507287e+07     0.000000     1.000000    68.000000   \n",
       "75%    7073.250000  1.756267e+07     0.000000     1.000000    78.000000   \n",
       "max    9431.000000  1.999983e+07     1.000000     1.000000    91.000000   \n",
       "\n",
       "           Albumin  Albumin/Creatinine, Urine   Creatinine      INR(PT)  \\\n",
       "count  8547.000000                1156.000000  9432.000000  9334.000000   \n",
       "mean      3.451082                 592.555623     1.809606     1.472087   \n",
       "std       0.759529                1752.909095     1.766590     0.775652   \n",
       "min       0.900000                   1.300000     0.000000     0.700000   \n",
       "25%       2.900000                  14.250000     0.900000     1.100000   \n",
       "50%       3.500000                  62.900000     1.200000     1.200000   \n",
       "75%       4.000000                 320.775000     2.000000     1.500000   \n",
       "max       5.600000               25235.000000    18.900000    14.100000   \n",
       "\n",
       "                PT  ...  Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "count  9316.000000  ...    9428.000000                        5224.000000   \n",
       "mean     16.207450  ...      31.481438                          57.653331   \n",
       "std       8.270952  ...      23.381033                          13.378989   \n",
       "min       8.500000  ...       1.000000                          11.000000   \n",
       "25%      12.200000  ...      16.000000                          49.000000   \n",
       "50%      13.700000  ...      25.000000                          56.000000   \n",
       "75%      16.500000  ...      40.000000                          64.000000   \n",
       "max     150.000000  ...     225.000000                         166.000000   \n",
       "\n",
       "       Arterial Blood Pressure systolic   Heart Rate  HrApacheIIScore  \\\n",
       "count                       5223.000000  9431.000000         5.000000   \n",
       "mean                         117.044036    85.585304         1.600000   \n",
       "std                           23.043919    18.476666         0.894427   \n",
       "min                            0.000000     0.000000         0.000000   \n",
       "25%                          102.000000    73.000000         2.000000   \n",
       "50%                          115.000000    84.000000         2.000000   \n",
       "75%                          130.000000    96.000000         2.000000   \n",
       "max                          332.000000   215.000000         2.000000   \n",
       "\n",
       "       Respiratory Rate  Temperature Celsius  hypertension  \\\n",
       "count       9429.000000          1765.000000   9432.000000   \n",
       "mean          19.706544            36.853541      0.528626   \n",
       "std            5.903741             4.406911      0.499206   \n",
       "min            0.000000             0.000000      0.000000   \n",
       "25%           16.000000            36.100000      0.000000   \n",
       "50%           19.000000            36.800000      1.000000   \n",
       "75%           23.000000            37.400000      1.000000   \n",
       "max           70.000000           101.300000      1.000000   \n",
       "\n",
       "       chronic_kidney_disease       sepsis  \n",
       "count             9432.000000  9432.000000  \n",
       "mean                 0.380831     0.114928  \n",
       "std                  0.485617     0.318952  \n",
       "min                  0.000000     0.000000  \n",
       "25%                  0.000000     0.000000  \n",
       "50%                  0.000000     0.000000  \n",
       "75%                  1.000000     0.000000  \n",
       "max                  1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631 (17.29%) people deceased, 7801 (82.71000000000001%) people survived.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a crosstab of 'dod' and 'gender'\n",
    "ct = pd.crosstab(df['dod'], df['gender'])\n",
    "\n",
    "# Plot the crosstab as a stacked bar chart\n",
    "ct.plot(kind='bar', stacked=True, figsize=(10, 7))\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Alive and Dead by Gender')\n",
    "plt.xlabel('Status (0: Dead, 1: Alive)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Gender', labels=['Male', 'Female'])  # Adjust labels if needed\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "deceased_count = len(df[df[\"dod\"] == 1])\n",
    "survived_count = len(df[df[\"dod\"] == 0])\n",
    "deceased_percentage = round(deceased_count / len(df) * 100, 2)\n",
    "survived_percentage = 100 - deceased_percentage\n",
    "\n",
    "print(f'{deceased_count} ({deceased_percentage}%) people deceased, {survived_count} ({survived_percentage}%) people survived.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dod', 'Unnamed: 0', 'subject_id'])\n",
    "y = df['dod']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Evaluation:\n",
      "Accuracy: 0.8351881293057764\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      1556\n",
      "           1       0.70      0.11      0.18       331\n",
      "\n",
      "    accuracy                           0.84      1887\n",
      "   macro avg       0.77      0.55      0.55      1887\n",
      "weighted avg       0.81      0.84      0.78      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1541   15]\n",
      " [ 296   35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary using 0.5 as threshold\n",
    "y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred_lin]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Linear Regression Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bin))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bin))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.8373078961314255\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      1556\n",
      "           1       0.64      0.17      0.26       331\n",
      "\n",
      "    accuracy                           0.84      1887\n",
      "   macro avg       0.74      0.57      0.59      1887\n",
      "weighted avg       0.81      0.84      0.80      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1525   31]\n",
      " [ 276   55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "log_reg = LogisticRegression(max_iter=10000)  # max_iter increased to ensure convergence\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nLogistic Regression Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Evaluation:\n",
      "Accuracy: 0.7657657657657657\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      1556\n",
      "           1       0.36      0.42      0.39       331\n",
      "\n",
      "    accuracy                           0.77      1887\n",
      "   macro avg       0.61      0.63      0.62      1887\n",
      "weighted avg       0.78      0.77      0.77      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1306  250]\n",
      " [ 192  139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tree))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Evaluation:\n",
      "Accuracy: 0.8468468468468469\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1556\n",
      "           1       0.67      0.25      0.36       331\n",
      "\n",
      "    accuracy                           0.85      1887\n",
      "   macro avg       0.76      0.61      0.64      1887\n",
      "weighted avg       0.83      0.85      0.82      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1515   41]\n",
      " [ 248   83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_forest))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_forest))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Evaluation:\n",
      "Accuracy: 0.8245892951775304\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1556\n",
      "           1       0.00      0.00      0.00       331\n",
      "\n",
      "    accuracy                           0.82      1887\n",
      "   macro avg       0.41      0.50      0.45      1887\n",
      "weighted avg       0.68      0.82      0.75      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1556    0]\n",
      " [ 331    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deep Learning Approach: NN - MLP (unfinished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance data handling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16610592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10464516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14644195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16049569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17223646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>138.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  dod  gender  age  Albumin  Creatinine  INR(PT)  \\\n",
       "0           0    16610592    0       0   64      3.4         0.8      1.0   \n",
       "1           1    10464516    0       1   67      4.6         0.8      1.3   \n",
       "2           2    14644195    0       1   38      2.8         0.7      1.4   \n",
       "3           3    16049569    0       0   52      2.5         0.3      1.1   \n",
       "4           4    17223646    0       0   69      2.8         0.5      1.0   \n",
       "\n",
       "     PT  Sodium  Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "0  16.5   138.0           11.0                               61.0   \n",
       "1  13.9   150.0           17.0                               69.0   \n",
       "2  14.1   136.0            8.0                               56.0   \n",
       "3  13.5   139.0            7.0                               75.0   \n",
       "4  11.3   138.0            9.0                               57.0   \n",
       "\n",
       "   Arterial Blood Pressure systolic  Heart Rate  Respiratory Rate  \\\n",
       "0                             131.0       103.0               7.0   \n",
       "1                              98.0        73.0              30.0   \n",
       "2                             115.0        98.0              18.0   \n",
       "3                             110.0       108.0              18.0   \n",
       "4                             125.0       109.0              17.0   \n",
       "\n",
       "   hypertension  chronic_kidney_disease  sepsis  Intercept  \n",
       "0             0                       0       0          1  \n",
       "1             1                       0       0          1  \n",
       "2             1                       0       1          1  \n",
       "3             0                       0       0          1  \n",
       "4             1                       0       0          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dod', 'Unnamed: 0', 'subject_id'])\n",
    "y = df['dod']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predict on the new test data\n",
    "# Model\n",
    "optimized_model = Sequential()\n",
    "\n",
    "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "optimized_model.add(Dropout(0.3))\n",
    "\n",
    "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "optimized_model.add(Dropout(0.3))\n",
    "\n",
    "optimized_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "optimized_model.summary()\n",
    "class_weights = {0: 1., 1: 2.}\n",
    "optimized_model.fit(X_train, Y_train, epochs=10, verbose=2, validation_split=0.1, batch_size=32,class_weight=class_weights)\n",
    "#optimized_model.evaluate(X_test, Y_test)\n",
    "optimized_model.evaluate(X_resampled_adasyn, y_resampled_adasyn) # use whole data set to train, no train test split\n",
    "\n",
    "y_pred = optimized_model.predict(X_pred)\n",
    "y_class_pred = (y_pred > 0.367).astype(int)\n",
    "list(y_class_pred).count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
