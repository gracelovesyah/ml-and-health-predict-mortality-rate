{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Exploration\n",
    "\n",
    "*by Grace*\n",
    "\n",
    "Hello Team,\n",
    "\n",
    "In this notebook, I've embarked on an initial exploration of various baseline models for our binary classification task. The primary goal was to establish a foundational understanding of the performance we can expect from some common algorithms, without any extensive tuning or optimisation.\n",
    "\n",
    "## Models Explored:\n",
    "- **Linear Regression**: Used as a binary classifier with a threshold.\n",
    "- **Logistic Regression**: A standard approach for binary classification tasks.\n",
    "- **Dummy Classifier**: Provides predictions based on simple rules, serving as a basic baseline.\n",
    "- **Decision Tree Classifier**: A simple and interpretable model.\n",
    "- **Random Forest Classifier**: An ensemble method using multiple decision trees.\n",
    "- **Support Vector Machine (SVM)**: Explored with a linear kernel.\n",
    "\n",
    "## Next Steps:\n",
    "- These models can serve as a starting point. There's ample room for optimisation, including hyperparameter tuning, feature engineering, and exploring more complex models.\n",
    "- It would be beneficial to delve deeper into each model's performance metrics, especially if our dataset has class imbalances.\n",
    "- Feedback and collaboration are encouraged. If anyone has insights or suggestions on improving these baseline models or wants to introduce other potential models, please share!\n",
    "\n",
    "Let's collaborate and refine our approach to achieve the best model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_final_AKI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- discover imbalance trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'subject_id', 'dod', 'gender', 'age', 'Albumin',\n",
       "       'Creatinine', 'INR(PT)', 'PT', 'Sodium', 'Urea Nitrogen',\n",
       "       'Arterial Blood Pressure diastolic', 'Arterial Blood Pressure systolic',\n",
       "       'Heart Rate', 'Respiratory Rate', 'hypertension',\n",
       "       'chronic_kidney_disease', 'sepsis', 'Intercept'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9.809000e+03</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.000000</td>\n",
       "      <td>9809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4904.000000</td>\n",
       "      <td>1.502895e+07</td>\n",
       "      <td>0.169130</td>\n",
       "      <td>0.595066</td>\n",
       "      <td>66.248649</td>\n",
       "      <td>3.457131</td>\n",
       "      <td>1.785574</td>\n",
       "      <td>1.459035</td>\n",
       "      <td>16.053879</td>\n",
       "      <td>138.392497</td>\n",
       "      <td>31.338974</td>\n",
       "      <td>57.022123</td>\n",
       "      <td>115.462942</td>\n",
       "      <td>85.214905</td>\n",
       "      <td>19.725762</td>\n",
       "      <td>0.532266</td>\n",
       "      <td>0.370068</td>\n",
       "      <td>0.113365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2831.758729</td>\n",
       "      <td>2.905536e+06</td>\n",
       "      <td>0.374886</td>\n",
       "      <td>0.490904</td>\n",
       "      <td>15.492567</td>\n",
       "      <td>0.718880</td>\n",
       "      <td>1.776733</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>8.201325</td>\n",
       "      <td>4.954862</td>\n",
       "      <td>23.540739</td>\n",
       "      <td>10.252333</td>\n",
       "      <td>17.183543</td>\n",
       "      <td>18.487896</td>\n",
       "      <td>6.036613</td>\n",
       "      <td>0.498983</td>\n",
       "      <td>0.482847</td>\n",
       "      <td>0.317055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000201e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2452.000000</td>\n",
       "      <td>1.251029e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4904.000000</td>\n",
       "      <td>1.507661e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7356.000000</td>\n",
       "      <td>1.757821e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9808.000000</td>\n",
       "      <td>1.999983e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    subject_id          dod       gender          age  \\\n",
       "count  9809.000000  9.809000e+03  9809.000000  9809.000000  9809.000000   \n",
       "mean   4904.000000  1.502895e+07     0.169130     0.595066    66.248649   \n",
       "std    2831.758729  2.905536e+06     0.374886     0.490904    15.492567   \n",
       "min       0.000000  1.000201e+07     0.000000     0.000000    18.000000   \n",
       "25%    2452.000000  1.251029e+07     0.000000     0.000000    57.000000   \n",
       "50%    4904.000000  1.507661e+07     0.000000     1.000000    68.000000   \n",
       "75%    7356.000000  1.757821e+07     0.000000     1.000000    78.000000   \n",
       "max    9808.000000  1.999983e+07     1.000000     1.000000    91.000000   \n",
       "\n",
       "           Albumin   Creatinine      INR(PT)           PT       Sodium  \\\n",
       "count  9809.000000  9809.000000  9809.000000  9809.000000  9809.000000   \n",
       "mean      3.457131     1.785574     1.459035    16.053879   138.392497   \n",
       "std       0.718880     1.776733     0.762548     8.201325     4.954862   \n",
       "min       0.900000     0.000000     0.500000     7.500000   103.000000   \n",
       "25%       3.000000     0.900000     1.100000    12.200000   136.000000   \n",
       "50%       3.500000     1.200000     1.200000    13.600000   139.000000   \n",
       "75%       4.000000     1.900000     1.500000    16.300000   141.000000   \n",
       "max       5.400000    21.400000    13.600000   150.000000   175.000000   \n",
       "\n",
       "       Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "count    9809.000000                        9809.000000   \n",
       "mean       31.338974                          57.022123   \n",
       "std        23.540739                          10.252333   \n",
       "min         1.000000                          13.000000   \n",
       "25%        16.000000                          55.000000   \n",
       "50%        24.000000                          56.000000   \n",
       "75%        39.000000                          57.000000   \n",
       "max       221.000000                         328.000000   \n",
       "\n",
       "       Arterial Blood Pressure systolic   Heart Rate  Respiratory Rate  \\\n",
       "count                       9809.000000  9809.000000       9809.000000   \n",
       "mean                         115.462942    85.214905         19.725762   \n",
       "std                           17.183543    18.487896          6.036613   \n",
       "min                            0.000000     0.000000          0.000000   \n",
       "25%                          112.000000    72.000000         16.000000   \n",
       "50%                          114.000000    84.000000         19.000000   \n",
       "75%                          117.000000    96.000000         23.000000   \n",
       "max                          332.000000   169.000000         69.000000   \n",
       "\n",
       "       hypertension  chronic_kidney_disease       sepsis  Intercept  \n",
       "count   9809.000000             9809.000000  9809.000000     9809.0  \n",
       "mean       0.532266                0.370068     0.113365        1.0  \n",
       "std        0.498983                0.482847     0.317055        0.0  \n",
       "min        0.000000                0.000000     0.000000        1.0  \n",
       "25%        0.000000                0.000000     0.000000        1.0  \n",
       "50%        1.000000                0.000000     0.000000        1.0  \n",
       "75%        1.000000                1.000000     0.000000        1.0  \n",
       "max        1.000000                1.000000     1.000000        1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1659 (16.91%) people deceased, 8150 (83.09%) people survived.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a crosstab of 'dod' and 'gender'\n",
    "ct = pd.crosstab(df['dod'], df['gender'])\n",
    "\n",
    "# Plot the crosstab as a stacked bar chart\n",
    "ct.plot(kind='bar', stacked=True, figsize=(10, 7))\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Alive and Dead by Gender')\n",
    "plt.xlabel('Status (0: Dead, 1: Alive)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Gender', labels=['Male', 'Female'])  # Adjust labels if needed\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "deceased_count = len(df[df[\"dod\"] == 1])\n",
    "survived_count = len(df[df[\"dod\"] == 0])\n",
    "deceased_percentage = round(deceased_count / len(df) * 100, 2)\n",
    "survived_percentage = 100 - deceased_percentage\n",
    "\n",
    "print(f'{deceased_count} ({deceased_percentage}%) people deceased, {survived_count} ({survived_percentage}%) people survived.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dod', 'Unnamed: 0', 'subject_id'])\n",
    "y = df['dod']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Evaluation:\n",
      "Accuracy: 0.8353720693170235\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      1617\n",
      "           1       0.87      0.08      0.14       345\n",
      "\n",
      "    accuracy                           0.84      1962\n",
      "   macro avg       0.85      0.54      0.52      1962\n",
      "weighted avg       0.84      0.84      0.77      1962\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1613    4]\n",
      " [ 319   26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary using 0.5 as threshold\n",
    "y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred_lin]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Linear Regression Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bin))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bin))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bin))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.8373078961314255\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      1556\n",
      "           1       0.64      0.17      0.26       331\n",
      "\n",
      "    accuracy                           0.84      1887\n",
      "   macro avg       0.74      0.57      0.59      1887\n",
      "weighted avg       0.81      0.84      0.80      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1525   31]\n",
      " [ 276   55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "log_reg = LogisticRegression(max_iter=10000)  # max_iter increased to ensure convergence\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nLogistic Regression Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Evaluation:\n",
      "Accuracy: 0.7657657657657657\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      1556\n",
      "           1       0.36      0.42      0.39       331\n",
      "\n",
      "    accuracy                           0.77      1887\n",
      "   macro avg       0.61      0.63      0.62      1887\n",
      "weighted avg       0.78      0.77      0.77      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1306  250]\n",
      " [ 192  139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_tree))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Evaluation:\n",
      "Accuracy: 0.8468468468468469\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1556\n",
      "           1       0.67      0.25      0.36       331\n",
      "\n",
      "    accuracy                           0.85      1887\n",
      "   macro avg       0.76      0.61      0.64      1887\n",
      "weighted avg       0.83      0.85      0.82      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1515   41]\n",
      " [ 248   83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_forest))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_forest))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Evaluation:\n",
      "Accuracy: 0.8245892951775304\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1556\n",
      "           1       0.00      0.00      0.00       331\n",
      "\n",
      "    accuracy                           0.82      1887\n",
      "   macro avg       0.41      0.50      0.45      1887\n",
      "weighted avg       0.68      0.82      0.75      1887\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1556    0]\n",
      " [ 331    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/graceliu/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deep Learning Approach: NN - MLP (unfinished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance data handling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>INR(PT)</th>\n",
       "      <th>PT</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16610592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10464516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14644195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16049569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17223646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>138.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  dod  gender  age  Albumin  Creatinine  INR(PT)  \\\n",
       "0           0    16610592    0       0   64      3.4         0.8      1.0   \n",
       "1           1    10464516    0       1   67      4.6         0.8      1.3   \n",
       "2           2    14644195    0       1   38      2.8         0.7      1.4   \n",
       "3           3    16049569    0       0   52      2.5         0.3      1.1   \n",
       "4           4    17223646    0       0   69      2.8         0.5      1.0   \n",
       "\n",
       "     PT  Sodium  Urea Nitrogen  Arterial Blood Pressure diastolic  \\\n",
       "0  16.5   138.0           11.0                               61.0   \n",
       "1  13.9   150.0           17.0                               69.0   \n",
       "2  14.1   136.0            8.0                               56.0   \n",
       "3  13.5   139.0            7.0                               75.0   \n",
       "4  11.3   138.0            9.0                               57.0   \n",
       "\n",
       "   Arterial Blood Pressure systolic  Heart Rate  Respiratory Rate  \\\n",
       "0                             131.0       103.0               7.0   \n",
       "1                              98.0        73.0              30.0   \n",
       "2                             115.0        98.0              18.0   \n",
       "3                             110.0       108.0              18.0   \n",
       "4                             125.0       109.0              17.0   \n",
       "\n",
       "   hypertension  chronic_kidney_disease  sepsis  Intercept  \n",
       "0             0                       0       0          1  \n",
       "1             1                       0       0          1  \n",
       "2             1                       0       1          1  \n",
       "3             0                       0       0          1  \n",
       "4             1                       0       0          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dod', 'Unnamed: 0', 'subject_id'])\n",
    "y = df['dod']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predict on the new test data\n",
    "# Model\n",
    "optimized_model = Sequential()\n",
    "\n",
    "optimized_model.add(Dense(128, input_shape=(5000,), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "optimized_model.add(Dropout(0.3))\n",
    "\n",
    "optimized_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "optimized_model.add(Dropout(0.3))\n",
    "\n",
    "optimized_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "optimized_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "optimized_model.summary()\n",
    "class_weights = {0: 1., 1: 2.}\n",
    "optimized_model.fit(X_train, Y_train, epochs=10, verbose=2, validation_split=0.1, batch_size=32,class_weight=class_weights)\n",
    "#optimized_model.evaluate(X_test, Y_test)\n",
    "optimized_model.evaluate(X_resampled_adasyn, y_resampled_adasyn) # use whole data set to train, no train test split\n",
    "\n",
    "y_pred = optimized_model.predict(X_pred)\n",
    "y_class_pred = (y_pred > 0.367).astype(int)\n",
    "list(y_class_pred).count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
